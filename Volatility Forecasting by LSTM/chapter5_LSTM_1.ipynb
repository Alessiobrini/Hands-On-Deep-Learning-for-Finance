{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, SimpleRNN\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix random seed for reproducibility\n",
    "#numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable definition\n",
    "data_folder = 'Data/' # Folder containing the dataset\n",
    "n_days = 1640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate the array\n",
    "dataset = np.empty((n_days, 0))\n",
    "\n",
    "# Create list to save assets names\n",
    "assets = []\n",
    "for f in sorted(os.listdir(data_folder)):\n",
    "\n",
    "    # Save assets names\n",
    "    assets.append(f.replace('.csv', ''))\n",
    "\n",
    "    # Load data\n",
    "    asset = pd.read_csv(data_folder + f, sep=',', usecols=[2, 3], engine='python')\n",
    "    asset = asset.values[:n_days]\n",
    " \n",
    "    # Ensure all data is float\n",
    "    asset = asset.astype('float32')\n",
    "    dataset = np.append(dataset, asset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize returns and volatility of the first asset\n",
    "i = 0\n",
    "plt.plot(dataset[:, 0], label='returns')\n",
    "plt.plot(dataset[:, 1], label='volatility')\n",
    "plt.legend()\n",
    "plt.title(assets[0])\n",
    "plt.xlabel('Time (days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "factor = 2\n",
    "\n",
    "# Calculate second raw moment\n",
    "M2 = np.mean(dataset ** 2, axis=0) ** (1/2)\n",
    "\n",
    "# Apply scaling\n",
    "dataset_norm = (1/factor) * (dataset / M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    \"\"\"\n",
    "    Function to convert series from dataset to supervised learning problem\n",
    "    \"\"\"\n",
    "    data_x, data_y = [], []\n",
    "\n",
    "    for i in range(len(dataset) - look_back):\n",
    "\n",
    "        # Create sequence of length equal to look_back\n",
    "        x = dataset[i:(i + look_back), :]\n",
    "        data_x.append(x)\n",
    "\n",
    "        # Take just the volatility for the target\n",
    "        data_y.append(dataset[i + look_back, 1::2])\n",
    "\n",
    "    return np.array(data_x), np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series to supervised learning problem\n",
    "look_back = 20\n",
    "X, y = create_dataset(dataset_norm, look_back)\n",
    "\n",
    "# Declare variables\n",
    "n_features = dataset.shape[1]\n",
    "n_assets = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "training_days = 300\n",
    "X_train, X_test = X[:training_days], X[training_days:]\n",
    "y_train, y_test = y[:training_days], y[training_days:]\n",
    "\n",
    "# Prepare the 3D input vector for the LSTM\n",
    "X_train = np.reshape(X_train, (-1, look_back, n_features))\n",
    "X_test = np.reshape(X_test, (-1, look_back, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(58,\n",
    "               input_shape=(look_back, n_features),\n",
    "               batch_size=batch_size,\n",
    "               stateful=True,\n",
    "               activity_regularizer=regularizers.l1_l2(),\n",
    "               recurrent_regularizer=regularizers.l1_l2()))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_assets, activation='sigmoid'))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the LSTM model\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "# Fit the model\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    model.fit(X_train,\n",
    "              Y_train,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              epochs=1,\n",
    "              verbose=0) # Verbosity mode 0: silent\n",
    "\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction (rolling test window)\n",
    "y_pred = np.empty((0, n_assets))\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_i = X_test[i].reshape(1, look_back, n_features)\n",
    "    predicted_output = model.predict(X_i, batch_size=batch_size)\n",
    "\n",
    "    # Reshape prediction to save into array\n",
    "    predicted_output = predicted_output.reshape(1,n_assets)\n",
    "    y_pred = np.append(y_pred, predicted_output, axis=0)\n",
    "\n",
    "y_pred = predicted_output.reshape(-1, n_assets)\n",
    "y_true = y_test.reshape(-1, n_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert scaling\n",
    "def invert_standardization(data, M2, factor):\n",
    "  \n",
    "    # Consider just volatility series\n",
    "    M2 = M2[1::2]\n",
    "\n",
    "    y_pred = factor * y_pred * M2\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# Apply inversion\n",
    "y_pred = invert_standardization(y_pred, M2, factor)\n",
    "y_true = invert_standardization(y_true, M2, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, folder):\n",
    "    \"\"\"\n",
    "    Function to calculate MSE and QLIKE\n",
    "    \"\"\"\n",
    "\n",
    "    mse = []\n",
    "    qlike = []\n",
    "\n",
    "    for i in range(0, 29):\n",
    "        mse_i = (y_true[:, i] - y_pred[:, i]) ** 2\n",
    "        qlike_i = np.log(y_pred[:, i]) + (y_true[:, i] /  y_pred[:, i])\n",
    "\n",
    "        # save results (point by point)\n",
    "        results = np.array([mse_i, qlike_i]).transpose()\n",
    "        np.savetxt(folder + assets[i] + '.csv', results, delimiter=',', header='MSE, Q-LIKE', fmt='%10.5f', comments='')\n",
    "\n",
    "        mse.append(np.mean(mse_i, axis=0))\n",
    "        qlike.append(np.mean(qlike_i, axis=0))\n",
    "\n",
    "    return mse, qlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply EVALUATE function to predictions\n",
    "mse, qlike = evaluate(y_true, y_pred, '1-BASE/')\n",
    "\n",
    "# save results\n",
    "results = np.array([mse, qlike]).transpose()\n",
    "np.savetxt('results/1.csv', results, delimiter=',', header='MSE,Q-LIKE', fmt='%10.5f', comments='')\n",
    "\n",
    "df = pd.DataFrame({'MSE': mse, 'QLIKE': qlike})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
