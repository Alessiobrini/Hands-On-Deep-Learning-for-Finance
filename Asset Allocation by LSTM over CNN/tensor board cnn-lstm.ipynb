{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read formatted data from csv files\n",
    "# Developed markets data will be used to train and validate the model\n",
    "dm_index = pd.read_csv('dm_index.csv',sep=',',index_col=0)\n",
    "dm_pe = pd.read_csv('dm_pe.csv',sep=',',index_col=0)\n",
    "dm_pb = pd.read_csv('dm_pb.csv',sep=',',index_col=0)\n",
    "dm_ps = pd.read_csv('dm_ps.csv',sep=',',index_col=0)\n",
    "\n",
    "# Emerging markets data will be used to test the model\n",
    "em_index = pd.read_csv('em_index.csv',sep=',',index_col=0)\n",
    "em_pe = pd.read_csv('em_pe.csv',sep=',',index_col=0)\n",
    "em_pb = pd.read_csv('em_pb.csv',sep=',',index_col=0)\n",
    "em_ps = pd.read_csv('em_ps.csv',sep=',',index_col=0)\n",
    "\n",
    "# compute one month forward returns\n",
    "dm_returns = dm_index.shift(-22)/dm_index -1\n",
    "em_returns = em_index.shift(-22)/em_index -1\n",
    "\n",
    "# drop all values which are na\n",
    "dm_returns = dm_returns.dropna()\n",
    "\n",
    "# now scale all of the above\n",
    "scaled_dm_returns = dm_returns.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "scaled_dm_pe = dm_pe.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "scaled_dm_pb = dm_pb.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "scaled_dm_ps = dm_ps.apply(lambda x:(x-x.min()) / (x.max()-x.min()),axis=1)\n",
    "\n",
    "# align the dataset\n",
    "scaled_dm_pe = scaled_dm_pe[scaled_dm_pe.index.isin(scaled_dm_returns.index)]\n",
    "scaled_dm_pb = scaled_dm_pb[scaled_dm_pb.index.isin(scaled_dm_returns.index)]\n",
    "scaled_dm_ps = scaled_dm_ps[scaled_dm_ps.index.isin(scaled_dm_returns.index)]\n",
    "\n",
    "# create dataset where the last column is output\n",
    "# split the dataset into 2/3 and 1/3 and make it into training and validation dataset\n",
    "def create_dataset(df1, df2, df3, df4, colidx):\n",
    "    df1 = np.array(df1.iloc[:,colidx])\n",
    "    df1 = df1.reshape((len(df1),1))\n",
    "    df2 = np.array(df2.iloc[:,colidx])\n",
    "    df2 = df2.reshape((len(df2),1))\n",
    "    df3 = np.array(df3.iloc[:,colidx])\n",
    "    df3 = df3.reshape((len(df3),1))\n",
    "    df4 = np.array(df4.iloc[:,colidx])\n",
    "    df4 = df4.reshape((len(df4),1))\n",
    "    dataset = np.hstack((df1,df2,df3,df4,df4))\n",
    "    splitpnt = len(dataset) *2 //3\n",
    "    train_data = dataset[:splitpnt,:]\n",
    "    val_data = dataset[splitpnt+1:,:]\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "n_steps = 22\n",
    "n_features = 4\n",
    "n_seq = 1\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(20, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3443 samples, validate on 1710 samples\n",
      "Epoch 1/5\n",
      "3443/3443 [==============================] - 3s 910us/sample - loss: 0.0428 - val_loss: 0.0104\n",
      "Epoch 2/5\n",
      "3443/3443 [==============================] - 1s 159us/sample - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 3/5\n",
      "3443/3443 [==============================] - 1s 155us/sample - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 4/5\n",
      "3443/3443 [==============================] - 1s 166us/sample - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 5/5\n",
      "3443/3443 [==============================] - 1s 149us/sample - loss: 0.0027 - val_loss: 0.0023\n",
      "Train on 3443 samples, validate on 1710 samples\n",
      "Epoch 1/5\n",
      "3443/3443 [==============================] - 1s 154us/sample - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 2/5\n",
      "3443/3443 [==============================] - 1s 151us/sample - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "3443/3443 [==============================] - 1s 153us/sample - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "3443/3443 [==============================] - 1s 182us/sample - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "3443/3443 [==============================] - 1s 170us/sample - loss: 0.0022 - val_loss: 0.0020\n",
      "United Kingdom done\n"
     ]
    }
   ],
   "source": [
    "    !rm -rf ./logs/\n",
    "    i = scaled_dm_returns.shape[1]-2\n",
    "    t, v = create_dataset(scaled_dm_pe, scaled_dm_pb, scaled_dm_ps, scaled_dm_returns, i)\n",
    "    tx, ty = split_sequences(t, n_steps)\n",
    "    vx, vy = split_sequences(v, n_steps)\n",
    "    tx = tx.reshape((tx.shape[0], n_seq, n_steps, n_features))\n",
    "    vx = vx.reshape((vx.shape[0], n_seq, n_steps, n_features))\n",
    "    filename = 'CNN-LSTM-' + scaled_dm_returns.columns[i] +'.json'\n",
    "    model.fit(tx,ty,epochs=150, validation_data=(vx, vy),callbacks=[tensorboard_callback])\n",
    "    history = model.fit(tx,ty,epochs=150, validation_data=(vx, vy))\n",
    "    pyplot.plot(history.history['loss'])\n",
    "    pyplot.plot(history.history['val_loss'])\n",
    "    pyplot.title('model train vs validation loss for ' + scaled_dm_returns.columns[i])\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "    pyplot.savefig(('CNN-LSTM-' + scaled_dm_returns.columns[i] + '.png'))\n",
    "    pyplot.close()\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    print(scaled_dm_returns.columns[i] + ' done')\n",
    "    with open(filename, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "    del history\n",
    "    del t\n",
    "    del v\n",
    "    del tx\n",
    "    del ty\n",
    "    del vx\n",
    "    del vy\n",
    "    del hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cdc382313d9bb1bc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cdc382313d9bb1bc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
